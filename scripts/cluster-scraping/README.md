# Ballarat Tool Library - Cluster Data Migration

This directory contains the distributed scraping system for migrating 1,209 tools from the existing Ballarat Tool Library MyTurn catalog to our alpha-1 system.

## Architecture

Based on the DATA_MIGRATION_PLAN.md, the migration uses a three-node distributed architecture:

```
WALNUT (192.168.1.27) - Coordinator
├── Main scraping orchestration
├── Content parsing with qwen2.5-coder (28 models)
└── Data normalization

IRONWOOD (192.168.1.113) - Processor  
├── Deep content analysis
├── Image processing and optimization
└── Data validation with deepseek-coder-v2 (12 models)

ROSEWOOD (192.168.1.22) - QA Validator
├── QA testing of scraped data
├── Data integrity checks with deepseek-r1 (9 models)
└── Import preparation for alpha-1
```

## Files

### Core Scripts
- **`walnut-coordinator.py`** - Main coordinator for catalog scraping (runs on WALNUT)
- **`ironwood-processor.py`** - Tool detail processing and image optimization (runs on IRONWOOD)  
- **`rosewood-qa.py`** - QA validation and import preparation (runs on ROSEWOOD)

### Deployment & Management
- **`deploy-cluster.sh`** - Deploy scripts to all cluster nodes with systemd services
- **`cluster-status.sh`** - Check status of services across the cluster (generated by deploy script)
- **`start-migration.sh`** - Start the complete migration process (generated by deploy script)

## Quick Start

### 1. Deploy to Cluster
```bash
cd scripts/cluster-scraping
./deploy-cluster.sh
```

This will:
- Deploy scripts to all available cluster nodes
- Set up systemd services for automatic execution
- Install required Python dependencies
- Create management scripts

### 2. Start Migration
```bash
./start-migration.sh
```

This initiates the complete migration workflow:
1. WALNUT begins catalog scraping (1,209 tools across ~81 pages)
2. IRONWOOD automatically processes tool details and downloads images
3. ROSEWOOD performs QA validation and generates import files

### 3. Monitor Progress
```bash
./cluster-status.sh
```

Check service status across all nodes and monitor the migration progress.

## Data Flow

```
MyTurn Catalog → WALNUT → IRONWOOD → ROSEWOOD → Alpha-1 Import
     ↓              ↓         ↓          ↓
1,209 tools    Scraping   Processing   QA & Prep   → SQL/JSON Files
```

## Output Structure

All data is stored in the shared NFS location: `/rust/containers/ballarat-scraping/`

```
ballarat-scraping/
├── scraping_progress.db          # SQLite tracking database
├── processed_data/               # Individual tool JSON files
├── tool_images/                  # Optimized tool images
├── qa_results/                   # QA validation reports
├── import_ready/                 # Final import files
│   ├── tools_import.sql         # SQL import script
│   ├── tools_import.json        # JSON import data
│   ├── category_mapping.json    # Category mappings
│   └── tool_images/             # Import-ready images
├── walnut_completed.signal       # WALNUT completion signal
└── ironwood_completed.signal     # IRONWOOD completion signal
```

## Migration Timeline

**Expected Duration**: 3-5 days

- **Day 1-2**: WALNUT catalog scraping and tool discovery
- **Day 3**: IRONWOOD detail processing and image optimization  
- **Day 4**: ROSEWOOD QA validation and import preparation
- **Day 5**: Final validation and import into alpha-1

## Target Data

Based on the MyTurn catalog analysis:

- **Total Tools**: 1,209 items
- **Categories**: Tools (1,009), Books & Media, Sports & Outdoors, Kitchen & Dining
- **Rich Metadata**: Manufacturer, product codes, specifications, weights, sizes
- **Visual Assets**: High-quality images hosted on AWS S3
- **Detailed Content**: Usage instructions, safety information, availability status

## Integration with Alpha-1

The migration generates import-ready files compatible with the alpha-1 database schema:

### SQL Import
- Direct INSERT statements for the `Tool` table
- Proper escaping and data validation
- Transaction-wrapped for safe import

### JSON Import  
- Structured data for API-based import
- Metadata and versioning information
- Compatible with alpha-1 API endpoints

### Image Integration
- Optimized images (max 800x600, JPEG, 85% quality)
- Proper naming convention for web serving
- Ready for deployment to alpha-1 public directory

## Monitoring & Debugging

### Service Logs
```bash
# On each host, check service logs:
sudo journalctl -u ballarat-walnut-coordinator -f     # WALNUT
sudo journalctl -u ballarat-ironwood-processor -f     # IRONWOOD  
sudo journalctl -u ballarat-rosewood-qa -f           # ROSEWOOD
```

### Progress Database
```bash
# Check progress in SQLite database:
sqlite3 /rust/containers/ballarat-scraping/scraping_progress.db

# View scraping progress:
SELECT page_number, items_found, status FROM scraping_progress;

# View discovered tools:
SELECT tool_id, tool_name, processed_by_ironwood, qa_by_rosewood FROM discovered_tools LIMIT 10;
```

### Signal Files
- `walnut_completed.signal` - Indicates WALNUT has finished scraping
- `ironwood_completed.signal` - Indicates IRONWOOD has finished processing

## Error Handling

The system includes comprehensive error handling:

- **Rate Limiting**: 1-2 second delays between requests to respect MyTurn servers
- **Retry Logic**: Failed requests are tracked and can be retried
- **Data Validation**: Multiple validation layers ensure data quality
- **Progress Tracking**: SQLite database tracks status of every tool
- **Graceful Failures**: Individual tool failures don't stop the entire migration

## Security & Ethics

- **robots.txt Compliance**: Respects website crawling policies
- **Rate Limiting**: Conservative request rates to avoid server overload
- **Public Data Only**: Only scrapes publicly available information
- **Privacy Compliance**: No personal data or private information collected

## Post-Migration

After successful migration:

1. **Import to Alpha-1**: Use generated SQL or JSON files to import tools
2. **Image Deployment**: Copy optimized images to alpha-1 public directory  
3. **Category Setup**: Use category mapping to configure tool categories
4. **Data Validation**: Verify imported tools display correctly in alpha-1
5. **Production Deployment**: Deploy updated alpha-1 with real tool data

## Troubleshooting

### Common Issues

**WALNUT not starting scraping:**
- Check network connectivity to MyTurn catalog
- Verify shared directory permissions
- Check Python dependencies are installed

**IRONWOOD not processing tools:**
- Ensure `walnut_completed.signal` file exists
- Check individual tool detail page access
- Verify image download permissions

**ROSEWOOD not generating imports:**
- Ensure `ironwood_completed.signal` file exists  
- Check processed data directory has JSON files
- Verify alpha-1 API connectivity for testing

### Manual Intervention

If needed, scripts can be run manually:

```bash
# On WALNUT:
cd /rust/containers/ballarat-scraping
python3 scripts/walnut-coordinator.py

# On IRONWOOD (after WALNUT completes):
python3 scripts/ironwood-processor.py

# On ROSEWOOD (after IRONWOOD completes):  
python3 scripts/rosewood-qa.py
```

## Support

For issues with the migration process:

1. Check service logs on relevant cluster nodes
2. Review progress database for specific tool failures
3. Consult DATA_MIGRATION_PLAN.md for detailed specifications
4. Monitor cluster status with provided management scripts

This migration system transforms the existing Ballarat Tool Library catalog into structured data ready for import into our modern alpha-1 system, preserving all tool information while adding enhanced categorization and optimized images.